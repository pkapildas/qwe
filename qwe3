Build a Convolution Neural Network to classify 6 classes of chess game images.
Parameters should not cross 300000
- Should not use more than 4 layers (except input and output, including convolution and dense layers)
- Use Adam Optimizer

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

# Load Data
train_dir="Chess/Train"
test_dir="Chess/Test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen=ImageDataGenerator(rescale=1/255.)
test_datagen=ImageDataGenerator(rescale=1/255.)


train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')

test_data=test_datagen.flow_from_directory(test_dir,
                                           target_size=(128,128),
                                           batch_size=32,
                                           class_mode='categorical')

# Build Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
base_model=Sequential([
                    Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),
                    MaxPool2D(),
                    Conv2D(16,3,activation='relu'),
                    MaxPool2D(),
                    Flatten(),
                    Dense(6, activation='softmax')

])

base_model.compile(loss='categorical_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

base_model.summary()

# fit model 
base_model.fit(train_data, epochs=10,
            steps_per_epoch=len(train_data),
            validation_data=test_data,
            validation_steps=len(test_data))
# EvaluateModel
base_model.evaluate(test_data)
# With respect to the above architecture, the model is overfitting
3 Improve the baseline model performance and save the weights of improved model
Conditions to consider:
Apply Data Augmentation if required
No parameter limit
Can use any number of layers
Use any optimizers of your choice
Use early stopping and save best model callbacks

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen=ImageDataGenerator(rescale=1/255.,
                                rotation_range=45,
                                width_shift_range=0.2,
                                height_shift_range=0.2,
                                shear_range=0.2,
                                zoom_range=0.2,
                                horizontal_flip=True,
                                fill_mode='reflect')

train_datagen=ImageDataGenerator(rescale=1/255.,zoom_range=0.2)


test_datagen=ImageDataGenerator(rescale=1/255.)
train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=64,
                                             class_mode='categorical')

test_data=test_datagen.flow_from_directory(test_dir,
                                           target_size=(128,128),
                                           batch_size=64,
                                           class_mode='categorical')

model1=Sequential([
                    Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),
                    Conv2D(32,3,activation='relu'),
                    MaxPool2D(),
                    Conv2D(64,3,activation='relu'),
                    MaxPool2D(),
                    Flatten(),
                    Dropout(0.2),
                    Dense(64,activation='relu'),
                    Dropout(0.2),
                    Dense(32,activation='relu'),
                    Dense(6, activation='softmax')

])


keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01),
                ModelCheckpoint('flower_best_transfer_model',monitor='val_loss',save_best_only=True)]

model1.compile(loss='categorical_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])
#model1.summary()
model1.fit(train_data, epochs=10,
            steps_per_epoch=len(train_data),
            validation_data=test_data,
            validation_steps=len(test_data),callbacks=keras_callback)

# The overfitting is reduced, but model performance is not improved , it is undesrfitting , 
  # but it is for only 10 epoch, changing the architecture may help,
  # So running this for more epoch may imprrove performance.
# Dataset size is very less, so transfer learning may help

# Students can use differnt combinations of layers to improve the model performance.
# Also more epochs will improve the model, but students dont have time for it in exam
# Need to award mark for an approach

Section C: Question 4:
Use the Transfer learning technique to improve the previous section modelâ€™s classification performance.

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

train_dir="Chess/Train"
test_dir="Chess/Test"


from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)

test_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)


train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(224,224),
                                             batch_size=32,
                                             class_mode='categorical')

test_data=test_datagen.flow_from_directory(test_dir,
                                           target_size=(224,224),
                                           batch_size=32,
                                           class_mode='categorical')


import tensorflow as tf
Base_model=tf.keras.models.load_model("base_model")

for layer_number, layer in enumerate(Base_model.layers):
    print(layer_number, layer.name, layer.trainable)


Base_model.summary()

inputs=tf.keras.layers.Input(shape=(224,224,3),name='input_layer')

#data_aug=data_augmentation(inputs)

x=Base_model(inputs,training=False)

p=tf.keras.layers.GlobalAveragePooling2D()(x)

outputs=tf.keras.layers.Dense(6,activation='softmax',name="output_layer")(p)

model=tf.keras.Model(inputs,outputs)

model.summary()


model.compile(loss="categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=['accuracy'])
keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01),
                ModelCheckpoint('flower_best_transfer_model',monitor='val_loss',save_best_only=True)]

history=model.fit(train_data,
                                         epochs=10,
                                         steps_per_epoch=len(train_data),
                                         validation_data=test_data,
                                         validation_steps=len(test_data),
                                         callbacks=keras_callback)

model.evaluate(test_data)
2s 676ms/step - loss: 0.9240 - accuracy: 0.6829
[0.9239882230758667, 0.6829268336296082]
validation loss is significantly reduced, but still model is overfitting, dropout and unfreezing batch normalization of convolution layer may help to reduce overfitting

Transfer learning with fine-tuning may also help

Section C: Question 5: (15 Marks)
Develop a Semantic segmentation model using Unet architecture on the given dataset.

import os
import cv2
from PIL import Image
import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
import segmentation_models as sm
from sklearn.model_selection import train_test_split
from PIL import Image
from tensorflow.keras.utils import normalize
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

image_dir='Unet_Dataset/glioma_img/'

mask_dir='Unet_Dataset/glioma_mask/'


SIZE=128 # for a quick training, for medical images it is better to keep image size big as it is

img_dataset=[]
mask_dataset=[]

images=os.listdir(image_dir)

for i,image_name in enumerate(images):
    if (image_name.split('.')[1]=='jpg'):
        image=cv2.imread(image_dir+image_name,0)
        
        image=Image.fromarray(image)
        image=image.resize((SIZE,SIZE))
        img_dataset.append(np.array(image))
        #img_dataset.append(image)

       
        
masks=os.listdir(mask_dir)

for i,image_name in enumerate(masks):
    if (image_name.split('.')[1]=='jpg'):
        image=cv2.imread(mask_dir+image_name,0)
        image=cv2.resize(image,(SIZE,SIZE))
        (thresh, bwimage) = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY) # make sure mask is binary image
        #bwimage=Image.fromarray(bwimage)
        #mask_dataset.append(np.array(bwimage))
        mask_dataset.append(bwimage)

img_dataset=np.array(img_dataset)
img_dataset=normalize(img_dataset)
img_dataset=np.expand_dims(img_dataset,3)

mask_dataset=np.array(mask_dataset)
mask_dataset=mask_dataset/255.
mask_dataset=np.expand_dims(mask_dataset,3)

print(img_dataset.shape)

print(mask_dataset.shape)

np.unique(mask_dataset[0,:,:,0]) # make sure mask is having only 0 and 1 for binary class

r1=np.random.randint(1,705,size=(1,2))
r1[0][0],r1[0][1]


r1=np.random.randint(1,705,size=(1,2))
plt.figure(figsize=(10,6))
plt.subplot(2,2,1)
plt.imshow(img_dataset[r1[0][0],:,:,:].reshape(128,128),cmap='gray')
plt.subplot(2,2,2)
plt.imshow(mask_dataset[r1[0][0],:,:,:].reshape(128,128),cmap='gray')
plt.subplot(2,2,3)
plt.imshow(img_dataset[r1[0][1],:,:,:].reshape(128,128),cmap='gray')
plt.subplot(2,2,4)
plt.imshow(mask_dataset[r1[0][1],:,:,:].reshape(128,128),cmap='gray')


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(img_dataset,mask_dataset,test_size=0.15,random_state=0)

BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)

# preprocess input
X_train_prepr = preprocess_input(x_train)
X_test_prepr = preprocess_input(x_test)

del(x_train)
del(x_test)
np.unique(y_test)

#model_resnet_backbone= sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True,classes=n_classes,activation='softmax')
model_resnet_backbone = sm.Unet(BACKBONE, input_shape=(128,128,1), encoder_weights=None, classes=1, activation='sigmoid')

#model_seg.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
#model_seg.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])
model_resnet_backbone.compile('Adam',loss=sm.losses.bce_jaccard_loss,metrics=[sm.metrics.iou_score])
#model_resnet_backbone.compile('Adam',loss=sm.losses.bce_jaccard_loss,metrics=[sm.metrics.iou_score])

X_train_prepr.shape


history=model_resnet_backbone.fit(X_train_prepr, 
         y_train,
         batch_size=2, 
         epochs=3,
         verbose=1,
         validation_data=(X_test_prepr, y_test))

#model_seg.compile(optimizer='Adam', loss=tf.keras.losses.BinaryCrossentropy())

n1=np.random.randint(0,len(X_test_prepr))
#n1=152
test_img=X_test_prepr[n1]
test_img1=np.expand_dims(test_img,0)
pred_img=model_resnet_backbone.predict(test_img1)
pred_img1=(pred_img[0,:,:,0]>0.5).astype(np.uint8)

plt.figure(figsize=(16,8))
plt.subplot(131)
plt.title('Original')
plt.imshow(test_img[:,:,0],cmap='gray')

plt.subplot(132)
plt.title('Mask Original')
plt.imshow(y_test[n1][:,:,0],cmap='gray')

plt.subplot(133)
plt.title('Segmented Image')
plt.imshow(pred_img1,cmap='gray')

-----
1. a) What are the causes of overfitting in a deep learning model?
High Model Complexity: Too many parameters compared to the amount of training data.
Insufficient Training Data: Not enough data to generalize well.
Noise in Training Data: Model learns noise and random fluctuations as patterns.
Lack of Regularization: No constraints on the model complexity.
Methods to Resolve Overfitting:
Dropout: Randomly dropping neurons during training to prevent co-adaptation.
Early Stopping: Monitoring the validation loss and stopping training when it starts increasing.

1. b) What is the usage of Convolution layer, pooling layer and dense layer in
Convolution Neural Network (CNN) architecture?
Convolution Layer: Extracts features from the input image by applying filters.
Pooling Layer: Reduces spatial dimensions, lowering the computational complexity and helping
with translation invariance.
Dense Layer (Fully Connected Layer): Combines features and makes predictions by learning
complex patterns.

1. c) What is the Vanishing Gradient Problem in deep learning models? How to get rid
of this?
Vanishing Gradient Problem: Gradients become very small during backpropagation, preventing
effective learning.
Solutions:
Use of Activation Functions like ReLU: Helps maintain gradients during backpropagation.
Batch Normalization: Normalizes inputs to each layer, reducing the risk of vanishing
gradients.
Weight Initialization Techniques: Proper initialization (e.g., He or Xavier initialization) to
maintain gradient magnitude.

1. d) List down various performance metrics used for object detection. What is the use
of non-maximal suppression in Object detection algorithms?
Performance Metrics:
Mean Average Precision (mAP): Measures the average precision across all classes.
Intersection over Union (IoU): Measures overlap between predicted and ground truth
boxes.
Precision and Recall: Evaluates the accuracy and completeness of the detections.
Non-Maximal Suppression (NMS):
Used to remove duplicate bounding boxes for the same object.
Keeps the box with the highest confidence score and suppresses the others.
1. e) What is the requirement of an activation function in deep neural network
architecture?
Introduces non-linearity, enabling the model to learn complex patterns.
Allows stacking multiple layers to form deep neural networks.
Activation Functions:
Tanh(): Ranges from -1 to 1, used in hidden layers for zero-centered output.
ReLU (Rectified Linear Unit): Outputs 0 for negative values, otherwise linear. Efficient and
reduces vanishing gradients.
Softmax(): Converts logits into probabilities, used in the output layer for multi-class
classification.

2. a) Explain the convolutional neural network architecture in detail.
Input Layer: Takes input images as a 3D matrix (height, width, channels).
Convolutional Layers: Extracts features using filters/kernels.
Activation Functions (e.g., ReLU): Introduces non-linearity.
Pooling Layers: Downsamples feature maps for spatial invariance.
Fully Connected Layers: Combines features and makes predictions.
Output Layer: Generates final predictions (e.g., using Softmax for classification).

2. b) Explain overfitting in neural networks? How to overcome the problem?
Overfitting: Model performs well on training data but poorly on new data.
Solutions:
Regularization (L1/L2): Adds a penalty for large weights.
Data Augmentation: Increases training data diversity.
Dropout: Randomly drops neurons during training.

2. c) What are the activation functions in neural networks? What is the use of these
activation functions?
Purpose: Introduce non-linearity, enabling the network to learn complex patterns.
Common Activation Functions:
Sigmoid: Outputs between 0 and 1, used in binary classification.
Tanh: Outputs between -1 and 1, zero-centered.
ReLU: Efficient and reduces vanishing gradient issues.
Softmax: Converts logits into probabilities for multi-class classification.

2. d) What is the difference between single stage and multi stage object detection
models?
Single Stage (e.g., YOLO, SSD):
Directly predicts bounding boxes and class probabilities.
Faster but less accurate for small objects.
Multi Stage (e.g., Faster R-CNN):
Two-stage process: Region Proposal followed by classification.
More accurate but slower due to the additional processing stage.

2. e) Briefly explain GANs? What are their advantages?
Generative Adversarial Networks (GANs):
Consists of a Generator and a Discriminator network.
Generator creates fake data, while Discriminator distinguishes between real and fake data.
Both networks are trained in a competitive manner.
Advantages:
Realistic Data Generation: High-quality synthetic data creation (e.g., images, music).
Data Augmentation: Useful for training models with limited data.
Creative Applications: Used in art generation, image super-resolution, and style transfer.

Explain the convolutional neural network architecture in detail.
A convolutional neural network (CNN), is a network architecture for deep learning which learns directly from data. CNNs are particularly useful for finding patterns in images to recognize objects.
They can also be quite effective for classifying non-image data such as audio, time series, and signal data

Kernel or Filter or Feature Detectors
In a convolutional neural network, the kernel is nothing but a filter that is used to extract the features from the images.

Formula = [i-k]+1

Stride
Stride is a parameter of the neural networkâ€™s filter that modifies the amount of movement over the image or video. we had stride 1 so it will take one by one. If we give stride 2 then it will take value by skipping the next 2 pixels.

Formula =[i-k/s]+1
Padding
Padding is a term relevant to convolutional neural networks as it refers to the number of pixels added to an image when it is being processed by the kernel of a CNN. For example, if the padding in a CNN is set to zero, then every pixel value that is added will be of value zero. When we use the filter or Kernel to scan the image, the size of the image will go smaller.

Pooling
Pooling in convolutional neural networks is a technique for generalizing features extracted by convolutional filters and helping the network recognize features independent of their location in the image.
Flatten
Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. The flattened matrix is fed as input to the fully connected layer to classify the image.
Layers used to build CNN
Convolutional neural networks are distinguished from other neural networks by their superior performance with image, speech, or audio signal inputs. They have three main types of layers, which are:

Convolutional layer
This layer is the first layer that is used to extract the various features from the input images. In this layer, We use a filter or Kernel method to extract features from the input image.
Pooling layer
The primary aim of this layer is to decrease the size of the convolved feature map to reduce computational costs. This is performed by decreasing the connections between layers and independently operating on each feature map. Depending upon the method used, there are several types of Pooling operations. We have Max pooling and average pooling.
Fully-connected (FC) layer
The Fully Connected (FC) layer consists of the weights and biases along with the neurons and is used to connect the neurons between two different layers. These layers are usually placed before the output layer and form the last few layers of a CNN Architecture.
Dropout
Another typical characteristic of CNNs is a Dropout layer. The Dropout layer is a mask that nullifies the contribution of some neurons towards the next layer and leaves unmodified all others.
Activation Function
An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuronâ€™s input to the network is important or not in the process of prediction. There are several commonly used activation functions such as the ReLU, Softmax, tanH, and the Sigmoid functions. Each of these functions has a specific usage.


Activation Function
An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuronâ€™s input to the network is important or not in the process of prediction. There are several commonly used activation functions such as the ReLU, Softmax, tanH, and the Sigmoid functions. Each of these functions has a specific usage.


GA

Coronavirus disease (COVID-19) has infected more than 1.3 million individuals all over the world and caused more than 106,000 deaths. One major hurdle in controlling the spreading of this disease is the inefficiency and shortage of medical tests. There have been increasing efforts on developing deep learning methods to diagnose COVID-19 based on CT scans. However, these works are difficult to reproduce and adopt since the CT data used in their studies are not publicly available. Besides, these works require a large number of CTs to train accurate diagnosis models, which are difficult to obtain.

Fortunately, one open source dataset is created with the help of a senior radiologist in Tongji Hospital, Wuhan, China, who has performed diagnosis and treatmen

import os
1. Data Preparation
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = "C:/Users/pkapi/Downloads/dataset/Train1"
test_dir = "C:/Users/pkapi/Downloads/dataset/Test"

# ImageDataGenerator with data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# For validation and test  rescaling  the images
test_datagen = ImageDataGenerator(rescale=1/255)

# Preparing train and test generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),  # Resize images to match input size
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
2. Defining CNN Architecture
# Preparing CNN architecture 
model = Sequential([
    Input(shape=(150, 150, 3)),  # Define input shape here
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),  # Dropout to reduce overfitting
    Dense(1, activation='sigmoid')
])

3. Compile the Model
apply binary cross-entropy loss for binary classification, with Adam optimizer.

# Compile  model
model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy', metrics=['accuracy'])

4. Callbacks
To saving and apply callbacks:

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# Define model callbacks
model_checkpoint = ModelCheckpoint("best_model.h5", save_best_only=True)
early_stopping_point = EarlyStopping(patience=10, restore_best_weights=True)

5. Train the Model
training model with callbacks:

# Train the model
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=test_generator,
    callbacks=[model_checkpoint, early_stopping_point]
6. Evaluate Model
Finally, evaluate the model's performance on the test set:

test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc:.2f}")
7. Plot Results
Visualize the training and validation accuracy and loss over epochs to understand how the model is performing.

import matplotlib.pyplot as plt

# Plotting accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)
plt.show()

8. Exploring Different Learning Factors and Regularization
To explore different learning factors, you can adjust the learning_rate parameter in the Adam optimizer. For regularization, you can add more Dropout layers or use L2 regularization in the Dense layers:

from tensorflow.keras import regularizers
# L2 regularization
model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))
from tensorflow.keras.optimizers import Adam

# learning rates to test
learning_rates = [0.001, 0.0005, 0.0001, 0.00001]
for lr in learning_rates:
    print(f"Testing learning rate: {lr}")
Testing learning rate: 0.001
Testing learning rate: 0.0005
Testing learning rate: 0.0001
Testing learning rate: 1e-05
model.compile(
    optimizer=Adam(learning_rate=lr),
    loss='sparse_categorical_crossentropy',  
    metrics=['accuracy']
)

# Train the model
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=test_generator,
    callbacks=[checkpoint_cb, early_stopping_cb]
)


import numpy as np
import matplotlib.pyplot as plt

# Predict the classes for the test data
predictions = model.predict(test_generator)  
predicted_classes = np.argmax(predictions, axis=1)  

# Get the true classes , class labels
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

 
print(f'Max predicted class index: {np.max(predicted_classes)}')
print(f'Max true class index: {np.max(true_classes)}')
print(f'Number of class labels: {len(class_labels)}')

# Function to plot images and predictions
def plot_predictions(generator, predictions, true_classes, class_labels, num_images=5):
    # Fetching batch of images and labels
    images, _ = next(generator)  

    plt.figure(figsize=(15, 15))

    for i in range(min(num_images, len(images))):   
        plt.subplot(1, num_images, i + 1)
        
        # Display the image
        plt.imshow(images[i])
        
        # Handle possible index issues
        try:
            true_label = class_labels[true_classes[i]]
            predicted_label = class_labels[predicted_classes[i]]
        except IndexError:
            print(f'IndexError: true_classes[i]={true_classes[i]}, predicted_classes[i]={predicted_classes[i]}')
            continue
        
        # Display Results ie,  true and predicted labels
        plt.title(f'True: {true_label}\nPred: {predicted_label}')
        plt.axis('off')
    
    plt.show()

# Display  predictions
plot_predictions(test_generator, predicted_classes, true_classes, class_labels, num_images=5)


1. Create a random tensor with 10 rows and 10 columns. Output random values should between range 1 and 10
a = tf.random.stateless_uniform([10,10], seed=(3,3), minval=1, maxval=10, dtype=tf.int32)
print(a)
2. Assign the first value (first row, first column) and last value(last row, last column) to ZERO
a = tf.Variable(a)
a[0,0].assign(0)
a[-1,-1].assign(0)
b = a.read_value()
print(b)
3. Create two tensor constants and perfrom subtraction and division
a = tf.constant(2)
b = tf.constant(3)

print("a + b :" , a.numpy() - b.numpy())
print("Addition with constants: ", a-b)
print("Addition with constants: ", tf.subtract(a, b))
print("a * b :" , a.numpy() / b.numpy())
print("Multiplication with constants: ", a/b)
print("Multiplication with constants: ", tf.divide(a, b))

#matrix multiple vs broad cast matrix
matrix1 = tf.random.stateless_uniform([4,4], seed=(3,3), minval=-10, maxval=10, dtype=tf.int32)

# Create another Constant that produces a 2x1 matrix.
matrix2 = tf.random.stateless_uniform([4,4], seed=(3,3), minval=-10, maxval=10, dtype=tf.int32)

# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.
# The returned value, 'product', represents the result of the matrix
# multiplication.
product = tf.matmul(matrix1, matrix2)
print("Multiplication with matrixes:", product)

3. Convert the RGB Image to Grayscale(For easier computation)
Hint: tf.image.rgb_to_grayscale(X_train)

The above code will give the result as tensor, take only the numpy part from it and procced.

x_train=tf.image.rgb_to_grayscale(X_train).numpy()
x_test=tf.image.rgb_to_grayscale(X_test).numpy()

4. Normalize the data so that data is in range 0-1
x_train=x_train/255.
x_test=x_test/255.
5. Reshape train and test images into one dimensional vector
xtrain=x_train.reshape(50000,32*32)
xtest=x_test.reshape(10000,32*32)
6. Print shape of data and number of images
print(xtrain.shape)
print('The number of images :',xtrain.shape[0])
 
7. One-hot encode the class vector
Hint: from tensorflow.keras.utils import to_categorical

from tensorflow.keras.utils import to_categorical
ytrain = to_categorical(y_train, num_classes=10)
ytest = to_categorical(y_test, num_classes=10)

print("Shape of y_train:", ytrain.shape)
print("One value of y_train:", ytrain[0])

08. Construct the Deep Neural Network of following architecture
    input_neurons x 64 x 32 x 32 x output_neurons
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

img_classifier=Sequential() 

img_classifier.add(Dense(units=64,activation='relu',input_dim=1024))

img_classifier.add(Dense(units=32,activation='relu'))

img_classifier.add(Dense(units=32,activation='relu'))

img_classifier.add(Dense(units=10,activation='softmax'))
img_classifier.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])
img_classifier.fit(xtrain,ytrain,batch_size=32,epochs=50,validation_data=(xtest, ytest))
img_classifier.evaluate(xtest, ytest)


import numpy as np

# Set random seed for reproducibility (optional)
np.random.seed(42)

# Initialize weights and biases
W1 = np.random.randn(10, 6)  # Input to Hidden Layer 1
b1 = np.random.randn(1, 6)

W2 = np.random.randn(6, 4)   # Hidden Layer 1 to Hidden Layer 2
b2 = np.random.randn(1, 4)

W3 = np.random.randn(4, 1)   # Hidden Layer 2 to Output Layer
b3 = np.random.randn(1, 1)

# Print the initialized weights and biases
print("W1 (Input -> Hidden1):\n", W1)
print("b1 (Bias for Hidden1):\n", b1)

print("W2 (Hidden1 -> Hidden2):\n", W2)
print("b2 (Bias for Hidden2):\n", b2)

print("W3 (Hidden2 -> Output):\n", W3)
print("b3 (Bias for Output):\n", b3)
----
done
