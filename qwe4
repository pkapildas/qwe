Process the dataset as questioned below using spark libraries.

# import statements

from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
from pyspark.ml.feature import StringIndexer
from pyspark.ml.feature import VectorAssembler
from pyspark.sql.functions import isnull, when, count, col
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.regression import LinearRegression

#prerequisite
# !pip install pyspark

sc = SparkContext.getOrCreate()
#spark = SparkSession(sc)
spark = SparkSession.builder.appName("LogisticRegression").getOrCreate()

#Create Spark Session & Load the provided dataset into spark-dataframe
#file_location = "/content/drive/MyDrive/sem3bda/Mumbai.csv" 
file_location =  "/FileStore/tables/Mumbai.csv"
file_type = "csv"

infer_schema = "True"
first_row_is_header = "True"
delimiter = ","

df = spark.read.format(file_type) \
   .option("inferSchema", infer_schema) \
   .option("header", first_row_is_header) \
   .option("sep", delimiter) \
   .load(file_location)

display(df.limit(10))


df.show()

df.display()

1. Show/print schema of the dataframe (1 marks)
df.printSchema()
# view 
df.createOrReplaceTempView("df")
spark.sql("DESCRIBE df").show()

2. Delete the column - "No. of Bedrooms" from the spark dataframe ( 1 marks)
df = df.drop("No. of Bedrooms")
display(df.limit(5))

# list of cols in alphabetic order
columns = df.columns
columns.sort()
print(','.join(columns)

3. Convert string column (i.e. "Location) into numeric values using StringIndexer transformer and make sure now DataFrame does not have any string columns anymore. (3marks)

from pyspark.ml.feature import StringIndexer
 
indexer = StringIndexer(inputCols=["Location"], outputCols=["Location_indexed"])
indexer_model = indexer.fit(df)
df = indexer_model.transform(df).drop("Location")

# Verify that there are no string columns left
print("DataFrame schema after converting string columns:")
df.printSchema()

4. Using vectorAssembler combines all columns (except target column i.e. 'Price') of spark DataFrame into single column (named as features). Make sure DataFrame now contains only two columns features and price. (4 marks)
from pyspark.ml.feature import VectorAssembler
features_col = df.columns
features_col.remove('Price')
assembler = VectorAssembler(inputCols= features_col, outputCol= "features")
df_assembled = assembler.transform(df).select("features", "Price")
df_assembled.printSchema()

display(df_assembled.limit(5))

5. Scale the data using StandardScaler. The input columns are the features, and the output column with the rescaled that will be included in the scaled_df will be named "features_scaled". (3 marks)
standardScaler = StandardScaler(inputCol="features", outputCol="features_scaled")
scaled_model = standardScaler.fit(df_assembled)
scaled_df = scaled_model.transform(df_assembled)
#scaled_df.show(5, truncate=False)

display(scaled_df.limit(5))

6. Split the vectorised dataframe into training and test sets with approx one third records being held for testing (2 marks)
# use randomSplit method
(training_data, test_data) = scaled_df.randomSplit([0.67, 0.33], seed=42)
print(f"Training Data Count: {training_data.count()}")
print(f"Test Data Count: {test_data.count()}")

training_data.show(5)

test_data.show(5)

7.. Build the LinerRegression object 'lr' by setting the required parameters. (3 marks)

# use below LinerRegression method
#lr = LinearRegression(featuresCol="features_scaled", labelCol="Price")
lr = LinearRegression(featuresCol="features_scaled", labelCol="Price")
lr_model = lr.fit(training_data)

print(f"Coefficients: {lr_model.coefficients}\n")
print(f"Intercept: {lr_model.intercept}\n")
print(f"RMSE: {lr_model.summary.rootMeanSquaredError}\n")
print(f"R-squared: {lr_model.summary.r2}")

8. Find rmse of trained LinearRegression model on test set (3 marks)

# use below RegressionEvaluator method
# evaluator = RegressionEvaluator(labelCol="Price", predictionCol="prediction", metricName="rmse")

predictions = lr_model.transform(test_data)

evaluator = RegressionEvaluator(labelCol="Price", predictionCol="prediction", metricName="rmse")
rmse = evaluator.evaluate(predictions)

print(f"Root Mean Squared Error (RMSE) on test set: {rmse}")
