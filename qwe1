Convert the following matrix to an orthogonal matrix using Gram Schmidt Process?
A = np.array( ((1,1,1), (-1, 0, 1), (1, 1, 2)))
A
u1, u2, u3 = A[:,0], A[:,1], A[:,2]
w1 =u1
# find magnitude of u1
mag_w1 = np.linalg.norm(w1) 
# do normalization 
v1= w1/mag_w1
print(v1.dot(v1))
# remove vector projection of u2 in v1 from u2
w2 =u2- (u2.dot(v1)) *v1 
mag_w2 = np.linalg.norm(w2) 
v2 = w2/mag_w2
v2.dot(v2)
# remove vector projection of u3 in v1 and v2 from u3
w3 = u3- ((u3.dot(v1)) *v1) -  ((u3.dot(v2)) *v2)
mag_w3 = np.linalg.norm(w3) 
v3 = w3/mag_w3
v3.dot(v3)

y = np.column_stack((v1,v2, v3))
print('result ')
print(y)

- Find Covariance matrix ?

x1 = np.array( [ [1.23, 2.12, 3.34, 4.5], [2.56, 2.89, 3.76, 3.95]])

print(x1)
np.cov(x1)

Define a loss function
Calculate derivative at each point
Run Gradient descent for Learning rate = 0.000001
Calculate the optimal value of w
For 60 Epoch plot cost

import matplotlib.pyplot as plt
height = np.array([167,145,170,180,189,155,163,178,173,176])
weight= np.array([83.5,72.5,85,90,94.5,77.5,81.5,89,86.5,88])

N =len(x)

learn_rate = 0.000001
error_rate =0.001
epochs = 60 
w=0
costs =[]
#Gradient Descent 
for epoch in range(epochs):
    predictions = w*height
    errors = weight - predictions
    cost = (errors **2 ).mean()
    costs.append(cost)
    gradient = -2 *(height *errors).mean()
    w-= learn_rate * gradient
    print(f"Epoch {epoch+1}/{epochs}, Cost :{cost}, w:{w}")
    

plt.title('Cost over Epochs ')
plt.xlabel('Epoch ')
plt.ylabel('Cost')
plt.plot( range(epochs), costs)
plt.show()

print(f"Optimal Value of w : {w}")


-Find singular value decomposition of 
from scipy.linalg import svd
A = np.array( ((1,2), (3 , 4), (5,6)))
A


Generate a dummy dataset using
np.random.seed(74)
X = np.random.randint(10,50,100).reshape(20,5)
Preprocess the data Preprocess the data by subtracting the mean and dividing by the standard deviation of each attribute value. The resulting data should be zero-mean with variance 1.
Compute the covriance matrix
obtain the eigenvalues and eigenvectors.
Find principle components.
X = np.random.randint(10,50,100).reshape(20,5)
mean = np.mean(X, axis =0)
std = np.std(X, axis =0)
Xcen = X-mean 
Xnorm = Xcen /std
XnormCov = np.cov(Xnorm, rowvar =False)
evals, evecs =np.linalg.eig(XnormCov)
s_index = np.argsort(evals)[::-1]
s_evals = evals[s_index]
s_devecs= evecs[s_index]
#np.transpose(s_devecs)
PCs =  np.transpose(np.dot(np.transpose(s_devecs), np.transpose(Xnorm)))

print(XnormCov)
print(evals)
print(evecs)
print(PCs)

Solve the following system $$\begin{pmatrix}

a = np.array([ [1,-1,1], [2,1, -3], [1,1,1] ])
a
b = np.array( [4,0,2])
b
x = np.linalg.solve(a,b)
print(x)
import sympy as sp
sp.init_printing()
x,y,z = sp.symbols('x,y,z')
sol = sp.solve([x+(-1)*y+ z-4, 

- Define function $f(w_1,w_2,w_3)= w_1^2+w_2^2+w_3^2$
- find$ \frac{\partial f}{\partial w_1},\frac{\partial f}{\partial w_2},\frac{\partial f}{\partial w_3}$

import sympy as sp
w1 = sp.symbols('w1')
w2 = sp.symbols('w2')
w3 = sp.symbols('w3')
def perform_op( w1, w2, w3):
    return w1*2+ w2*2+ w3*2
print(sp.diff(perform_op(w1, w2, w3), w1))
print(sp.diff(perform_op(w1, w2, w3), w2))
print(sp.diff(perform_op(w1, w2, w3), w3))
                2*x + y + (-3)*z -0 ,
                x+y+z -2 ], [x,y,z])
print(sol)

-Define the following function
$
f(x) =\begin{cases}
 & 0.5x , \text{ if }  x \leq0 \\
 & 1 ,\text{ if }  x > 0
\end{cases} \text { find }  f(-3) $ $ \text{and}$ $ f(2) $
sol
import sympy as sp

x = sp.symbols('x')
def do_fn(x):
    if x<=0 :
        return 0.5*x
    else :
        return 1

print(do_fn(-3))
print(do_fn(2))

----
(b) function optimization problem  or

PCA step by step on a iris dataset and capture 95 % variance(15 marks)
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler

# Step 1: Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target
feature_names = iris.feature_names

# Step 2: Standardize the Data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 3: Compute the Covariance Matrix
cov_matrix = np.cov(X_scaled.T)

# Step 4: Compute the Eigenvectors and Eigenvalues
eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)

# Step 5: Select Principal Components
# Sort eigenvalues and eigenvectors in descending order
sorted_indices = np.argsort(eigenvalues)[::-1]
eigenvalues = eigenvalues[sorted_indices]
eigenvectors = eigenvectors[:, sorted_indices]

# Select the top k eigenvectors based on the explained variance ratio
total_variance = np.sum(eigenvalues)
explained_variance_ratio = eigenvalues / total_variance
cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)
k = np.argmax(cumulative_explained_variance_ratio >= 0.95) + 1

# Step 6: Project Data onto Principal Components
projection_matrix = eigenvectors[:, :k]
X_pca = X_scaled.dot(projection_matrix)

# Display the explained variance ratio and cumulative explained variance ratio
print("Explained Variance Ratio:", explained_variance_ratio[:k])
print("Cumulative Explained Variance Ratio:", cumulative_explained_variance_ratio[:k])
----
3. Consider the data given below and fit a linear regression line y=ax+b using gradient descent.

X
0
0.4
0.6
1

Y
0
1
0.48
0.95

Initialize the weights a and b to 0.8, 0.2 respectively.

Update the weights such that the error is minimum using gradient descent.

Use the function sum of squared errors $ yâˆ’y^2$ where $y^$ is the y-predicted value and y is the actual given y.

Plot the linear regression line after updating the values of a and b in two iterations.

---
import numpy as np
import matplotlib.pyplot as plt

# Define the dataset
X = np.array([0, 0.4, 0.6, 1])
Y = np.array([0, 1, 0.48, 0.95])

# Define initial weights
a = 0.8
b = 0.2

# Define learning rate and number of iterations
learning_rate = 0.1
iterations = 2

# Define function to calculate sum of squared errors
def sum_squared_errors(Y, Y_pred):
    return np.sum((Y - Y_pred) ** 2)

# Perform gradient descent
for i in range(iterations):
    # Calculate predicted values of y
    Y_pred = a * X + b

    # Calculate gradients
    gradient_a = -2 * np.sum((Y - Y_pred) * X)
    gradient_b = -2 * np.sum(Y - Y_pred)

    # Update weights
    a -= learning_rate * gradient_a
    b -= learning_rate * gradient_b

    # Print the updated weights and sum of squared errors
    print(f"Iteration {i+1}: a = {a}, b = {b}, Sum of Squared Errors = {sum_squared_errors(Y, Y_pred)}")

# Plot the original data points
plt.scatter(X, Y, color='blue', label='Original data points')

# Plot the linear regression line
plt.plot(X, a*X + b, color='red', label='Linear regression line')

# Add labels and legend
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Linear Regression using Gradient Descent')
plt.legend()

# Show plot
plt.grid(True)
plt.show()

