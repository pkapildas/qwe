 Section B: Question No:2 (10 marks)
This dataset has images from 8 different classes of household garbage; battery, biological, clothes, green-glass, metal, paper, plastic and shoes.
Garbage Recycling is a key aspect of preserving our environment. To make the recycling process possible/easier, the garbage must be sorted to groups that have similar recycling process
Dataset_Folder Name: Garbage classes 120 images are there in every train grabage class folder.
Conditions to consider:
--Parameters should not cross 300000
--Should not use more than 4 layers (except input and output, including convolution and dense layers)
--Use Adam Optimizer
---
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

!ls /content/drive/MyDrive/dl_oct24/oct24data/garbage_classes/
train_dir= '/content/drive/MyDrive/dl_oct24/oct24data/garbage_classes/train'
test_dir= '/content/drive/MyDrive/dl_oct24/oct24data/garbage_classes/test'

#CNN = Convolution Neural Network
train_datagen=ImageDataGenerator(rescale=1/255.,validation_split=0.2)
test_datagen=ImageDataGenerator(rescale=1/255.)

# part 2 --------------------------------------------------------------------# Load training and validation datasets using subset split
train_data = train_datagen.flow_from_directory( train_dir , target_size=(128, 128), batch_size=32, class_mode='categorical', subset='training')
valid_data = train_datagen.flow_from_directory( train_dir , target_size=(128, 128), batch_size=32, class_mode='categorical', subset='validation')  # Validation set (20% of data)
test_data  =  test_datagen.flow_from_directory(   test_dir, target_size=(128, 128), batch_size=32, class_mode='categorical')

# part 3 ----------------------------------------------------------------------------- Build Model
model1=Sequential()
model1.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu',input_shape=(128,128,3)))
model1.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))
model1.add(GlobalAveragePooling2D())
model1.add(Dense(32,activation='relu'))
model1.add(Dense(8,activation='softmax'))       #because 8 class of garbage we have to find
#model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
#Infer the model summary
model1.summary()


 part 3 -----------------------------------------------------------------------------Compile the model
model1.compile(  optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
# model1.compile(optimizer='adam',loss='binary_crossentropy'     ,metrics=['accuracy']) # Changed loss to binary_crossentropy

# part 3 ---------------------------------------------------------------------------- fit the model for train data and run it for 5 epoch
history = model1.fit(train_data,batch_size=32,epochs=2,validation_data=valid_data)  #32 batch size # epoch 500 in realtime   # 32*24 = 768

# evaluate the model for test data # Justify whether the model is overfitting or underfitting
model1.evaluate(test_data)   # accuracy: 0.2237 - loss: 1.8832 #running good because we accuracy & loss are almost same
'''
# Step 4 ---------------------------------------------------------------------------- Evaluate the model on test data
test_loss, test_acc = model1.evaluate(test_data)
print(f"Test Accuracy: {test_acc:.4f}")

# Justify Overfitting or Underfitting
train_acc = history.history['accuracy'][-1]
val_acc = history.history['val_accuracy'][-1]

if train_acc > val_acc + 0.1:
    print("The model may be overfitting.")
elif val_acc > train_acc:
    print("The model may be underfitting.")
else:
    print("The model has a good balance between bias and variance.")

# plot to see overfitting or underfitting
#plt.plot(history.history['accuracy'], label='accuracy')
#plt.plot(history.history['val_accuracy'], label='val_accuracy')
import matplotlib.pyplot as plt
train_loss = history.history['loss']
val_loss = history.history.get('val_loss', None)
train_acc = history.history['accuracy']
val_acc = history.history.get('val_accuracy', None)

# Plot Loss Curve
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))  # Increased figure height
plt.subplot(1, 2, 1)  # Create subplots for accuracy and loss
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch') ; plt.ylabel('Accuracy') ; plt.legend() ; plt.title('Accuracy')
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss')
plt.tight_layout() # Adjust layout to prevent overlapping
plt.show()'''


---
Section B: Question No:3 (20 marks)
Improve the baseline model (model build in question2) performance and save the weights of improved model

Conditions to consider:
Apply Data Augmentation if required
No parameter limit
Can use any number of layers
Use any optimizers of your choice
Use early stopping and save best model callbacks

---
#Section B: Question No:3 (20 marks)
#Improve the baseline model (model build in question2) performance and save the weights of improved model
#Conditions to consider:
#Apply Data Augmentation if required
#No parameter limit
#Can use any number of layers
#Use any optimizers of your choice
#Use early stopping and save best model callbacks

#augment only the train
train_datagen1=ImageDataGenerator(rescale=1/255.,rotation_range=45,width_shift_range=0.2,height_shift_range=0.2,
                                  shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='reflect',validation_split=0.2)
train_data1=train_datagen1.flow_from_directory(train_dir,target_size=(128,128),batch_size=32,class_mode='categorical',subset='training')
valid_data1=train_datagen1.flow_from_directory(train_dir,target_size=(128,128),batch_size=32,class_mode='categorical',subset='validation')
#same test data
model2=Sequential()
model2.add(Conv2D(128,kernel_size=(3,3),padding='same',activation='relu',input_shape=(128,128,3)))
model2.add(BatchNormalization())
model2.add(MaxPool2D())
model2.add(Dropout(0.3))
model2.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu',input_shape=(128,128,3)))
model2.add(BatchNormalization())
model2.add(MaxPool2D())
model2.add(Dropout(0.3))
model2.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))
model2.add(BatchNormalization())
model2.add(MaxPool2D())
#model2.add(Dropout(0.3))

model2.add(GlobalAveragePooling2D())
#model2.add(Dropout(0.3))
model2.add(Dense(32,activation='relu'))
model2.add(BatchNormalization())
model2.add(Dropout(0.5))
model2.add(Dense(8,activation='softmax'))
model2.summary()
#sgd - STOCHASTIC GRADIENT DESCENT
#SGD=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.05)
#model2.compile(optimizer=SGD,loss='categorical_crossentropy',metrics=['accuracy'])
model2.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])
#keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01), ModelCheckpoint('garbage_best_transfer_model',monitor='val_loss',save_best_only=True)]
keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01), ModelCheckpoint('garbage_best_transfer_model.keras',monitor='val_loss',save_best_only=True)]
#Infer the model summary
# fit the model for train data
model2.fit(train_data1,batch_size=32,epochs=2,validation_data=valid_data1,callbacks=keras_callback)
# evaluate the model for test data
# Justify whether the model is improved then the earlier model
model2.evaluate(test_data)
##plot PUTTING IN HISTORY


train_datagen1=ImageDataGenerator(rescale=1/255.,rotation_range=45,width_shift_range=0.2,height_shift_range=0.2,
                                  shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='reflect',validation_split=0.2)
train_data1=train_datagen1.flow_from_directory(train_dir,target_size=(128,128),batch_size=32,class_mode='categorical',subset='training')
valid_data1=train_datagen1.flow_from_directory(train_dir,target_size=(128,128),batch_size=32,class_mode='categorical',subset='validation')

test_datagen=ImageDataGenerator(rescale=1/255.)
test_data=test_datagen.flow_from_directory(test_dir,target_size=(128,128),batch_size=32,class_mode='categorical')

# load the model and add 2 layers
#(1. do global Average pooling, 2. add the output layer )
# add the input layer with image size (224,224,3) and then add the pre-trained model (Hint: Base_model(inputs,training=False))
# do global Average pooling (Hint: tf.keras.layers.GlobalAveragePooling2D()(previous layer o/p))
# add output layer
# Create the model with [tf.keras.Model(inputs,outputs)]
# Infer the model summary

base_model_path = '/content/drive/MyDrive/dl_oct24/base_model' #Corrected path
cust_model=tf.keras.models.load_model(base_model_path)
cust_model.summary()


inputs=tf.keras.Input((224,224,3))
x=cust_model(inputs,training=False)                            # add the pre-trained model
x=GlobalAveragePooling2D()(x)                                  # do global Average pooling
outputs=Dense(8,activation='softmax')(x)                       # add output layer (since multiple layer -- its softmax)
cust_model_1=tf.keras.Model(inputs=inputs,outputs=outputs)     # create the model
cust_model_1.summary() 


# compile the model
# Use model checkpoint to fetch the best model
# fit the model to train data
    #epochs=10,
    #validation_data=test_data,
    #callbacks=keras_callback

# compile the model
cust_model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

keras_callback = [EarlyStopping(monitor='val_loss', mode='min', patience=5, min_delta=0.01),
                  ModelCheckpoint('garbage_best_transfer_model_1', monitor='val_loss', save_best_only=True)]

cust_model_1.fit(train_data1, batch_size=32, epochs=2, validation_data=valid_data1, callbacks=keras_callback)

cust_model_1.evaluate(test_data)
----
Section C: Question 5: (15 Marks)
Develop a Semantic segmentation model using Unet architecture on the given dataset.

Dataset contains the images and the corresponding masks. Find the dataset under the folder “Unet_Dataset”. 1141 Glioma tumor images and its corresponding masks are provided.

Students can make use of pre-trained Unet segmentation model using the library
!pip install segmentation-models==1.0.1
!pip install opencv-python
os.environ["SM_FRAMEWORK"] = "tf.keras"

import numpy as np
import tensorflow as tf
import keras
import segmentation_models as sm
import cv2 #Import cv2

# Try to import TensorFlow Advanced Segmentation Models (TASM)
try:
    import tensorflow_advanced_segmentation_models as tasm
    tasm_version = tasm.__version__
except ImportError:
    tasm_version = "TASM is not installed."

# Print version information
print("NumPy Version:", np.__version__)
print("TensorFlow Version:", tf.__version__)
print("Keras Version:", keras.__version__)
print("Segmentation Models Version:", sm.__version__)
print("TASM Version:", tasm_version)

import segmentation_models as sm
NumPy Version: 1.26.4
TensorFlow Version: 2.18.0
Keras Version: 3.8.0
Segmentation Models Version: 1.0.1
TASM Version: TASM is not installed.
# Define paths (adjust if needed)
image_dir ='/content/drive/MyDrive/dl_oct24/Unet_Dataset/glioma_img/'
mask_dir = '/content/drive/MyDrive/dl_oct24/Unet_Dataset/glioma_mask/'
SIZE = 128

# List and filter image and mask files
images = os.listdir(image_dir)
filtered_images = [img for img in images if '(1)' not in img]

masks = os.listdir(mask_dir)
filtered_masks = [m for m in masks if '(1)' not in m]

# Initialize datasets
img_dataset = []
mask_dataset = []

# Load and preprocess images
for image_name in filtered_images:
#for i,image_name in enumerate(images):
    if image_name.split('.')[1] == 'jpg':
        image = cv2.imread(image_dir + image_name, 0)
        image = Image.fromarray(image) # PIL Image is used.
        image = image.resize((SIZE, SIZE))
        img_dataset.append(np.array(image))
# Load and preprocess masks
for mask_name in filtered_masks:
#for i,image_name in enumerate(masks):
    if mask_name.split('.')[1] == 'jpg':
        mask = cv2.imread(mask_dir + mask_name, 0)
        mask = Image.fromarray(mask) # PIL Image is used.
        mask = mask.resize((SIZE, SIZE))
        mask_dataset.append(np.array(mask))

img_dataset=np.array(img_dataset)
img_dataset1=img_dataset/255.
img_dataset1=np.expand_dims(img_dataset,axis=-1)
img_dataset2=np.repeat(img_dataset1,3,axis=-1)

mask_dataset=np.array(mask_dataset)
mask_dataset1=mask_dataset/255.
mask_dataset2=np.expand_dims(mask_dataset1,axis=-1)
mask_dataset2=np.where(mask_dataset2>0.5,1.0,0.0) # Converting to binary #maintain float

mask_dataset3=mask_dataset2.copy()
print(img_dataset2.shape)
print(mask_dataset2.shape)

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(img_dataset2,mask_dataset2,test_size=0.2,random_state=0)

#take the pre-trained model as resnet34 and do pre-processing
BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)
# use the preprocessed train input for model fitting
X_train_prepr = preprocess_input(xtrain)
X_test_prepr = preprocess_input(xtest)
X_train_prepr.shape

#load the Unet model using the below syntax
model= sm.Unet(BACKBONE, input_shape=(128,128,3),
                                encoder_weights=None, classes=1, activation='sigmoid')
# Model compilation with the following specifications
#Hint: optimizer='Adam'
#    loss=sm.losses.bce_jaccard_loss
#    metrics=[sm.metrics.iou_score])
model.compile(optimizer='adam',loss=sm.losses.bce_jaccard_loss,metrics=[sm.metrics.iou_score])
# fit the model for X_train_prepr and y_train.
# use batch_size=2 and epochs=5 (maximum)

model.fit(X_train_prepr,ytrain,batch_size=32,epochs=2,validation_data=(X_test_prepr,ytest))



import segmentation_models as sm
MArch 2024 FOOD Classifier 
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
#os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
#os.environ["CUDA_VISIBLE_DEVICES"]="0

train_dir="Food classification/Train"
test_dir="Food classification/Test"


train_datagen=ImageDataGenerator(rescale=1/255.)
train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')

test_datagen=ImageDataGenerator(rescale=1/255.)
test_data=test_datagen.flow_from_directory(test_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')

#create the sequestial model with 2-3 layers ov Conv2D and Pooling
#Compile the model
#Infer the model summary
model = Sequential()
model.add(Conv2D(64,(3,3), activation='relu', input_shape=(128,128,3)))
model.add(MaxPool2D(2,2))
model.add(Conv2D(32,(3,3), activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(5, activation='softmax'))

model.summary()
$$$Model: "sequential_4"

# fit the model for train data and run it for 5 epoch
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model = model.fit(train_data, batch_size=16, epochs=5, validation_data=test_data, steps_per_epoch=90//16, validation_steps=50//16)

 evaluate the model for test data
# Justify whether the model is overfitting or underfitting
Inference
The model is over fitting as training accuracy is nearly 80% while validation accuracy is only 40%
Section B: Question No:3 (20 marks)
Improve the baseline model (model build in question
train_datagen_1=ImageDataGenerator(rescale=1/255.,
                                  rotation_range=45,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='reflect')
train_data_1=train_datagen_1.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')
test_datagen_1=ImageDataGenerator(rescale=1/255.,
                                  rotation_range=45,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='reflect')
test_data_1=test_datagen_1.flow_from_directory(test_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')

model1 = Sequential()
model1.add(Conv2D(64,(3,3), activation='relu', input_shape=(128,128,3)))
model1.add(MaxPool2D(2,2))
model1.add(Conv2D(32,(3,3), activation='relu'))
model1.add(MaxPool2D(2,2))
model1.add(Flatten())
model1.add(Dense(128, activation='relu'))
model1.add(Dense(5, activation='softmax'))

model1.summary()

#create the sequestial model with 2-3 layers ov Conv2D and Pooling
#Compile the model
#Use callback to fetch the best model


keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01),
                ModelCheckpoint('best_transfer_model.keras',monitor='val_loss',save_best_only=True)]
# fit the model for train data and run it for 5 epoch
model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model1 = model1.fit(train_data_1, batch_size=16, epochs=5, validation_data=test_data_1, steps_per_epoch=90//16, validation_steps=50//16, callbacks=keras_callback)

#Infer the model summary
# fit the model for train data and run it for 5 epoch
# evaluate the model for test data
# Justify whether the model is improved then the earlier model
Inference
The accuracy dropped as data augumentation increases the diversity in the images, but the training time is kept constant. As complexity is increased, the accuracy drops.

Section C: Question 4:
Use the Transfer learning technique to improve the previous section model’s classification performance. The pre-trained models weights are given to you. The architecture of pre-trained model till convolution layers and its corresponding weights are already saved under the folder ‘base_model’. The given model convolution layers already freezed. (Note: This pre-trained model provided is MobileNet).
Load these weights along with architecture using the following syntax:

cust_model=tf.keras.models.load_model("base_model")

“base_model” is the folder name under all the required models files are exist.
Design the remaining layers of network in your own way (from flattening to output layer) and train only its weights with the dataset given.

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
#os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
#os.environ["CUDA_VISIBLE_DEVICES"]="0"
train_dir="Food classification/Train"
test_dir="Food classification/Test"
#Load the pre-trained model using the below command
cust_model=tf.keras.models.load_model("base_model")
cust_model.summary()

# load the model and add 2 layers (1. do global Average pooling, 2. add the output layer as dense layer )
# add the input layer with image size (224,224,3) and then add the pre-trained model (Hint: Base_model(inputs,training=False))
# do global Average pooling (Hint: tf.keras.layers.GlobalAveragePooling2D()(previous layer o/p))
# add denselayer with activation function= softmax and with number of output classes)
# Create the model with [tf.keras.Model(inputs,outputs)]
# Infer the model summary

cust_model.trainable = False

x = GlobalAveragePooling2D()(cust_model.output)
output = Dense(5, activation='softmax')(x)
model2 = tf.keras.Model(inputs=cust_model.input, outputs=output)
model2.summary()

model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# compile the model
# Use model checkpoint to fetch the best model
# fit the model to train data 
    #epochs=2,
    #validation_data=test_data,
    #callbacks=keras_callback
train_datagen_1=ImageDataGenerator(rescale=1/255.,
                                  rotation_range=45,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='reflect')
train_data_1=train_datagen_1.flow_from_directory(train_dir,
                                             target_size=(224,224),
                                             batch_size=32,
                                             class_mode='categorical')
test_datagen_1=ImageDataGenerator(rescale=1/255.,
                                  rotation_range=45,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='reflect')
test_data_1=test_datagen_1.flow_from_directory(test_dir,
                                             target_size=(224,224),
                                             batch_size=32,
                                             class_mode='categorical')
keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=2,min_delta=0.01),
                ModelCheckpoint('./best_tf_model',monitor='val_loss',save_best_only=True)]

dir_path = 'ESA/Question-DL-Mar2024/Question/best_transfer_model'
model2.fit(train_data_1, batch_size=16, epochs=5, validation_data=test_data_1, callbacks=keras_callback)

Inference
Using the transfer learning, the classification val accuracy improved to 86%

Section C Q5
Section C: Question 5: (15 Marks)
Develop a Semantic segmentation model using Unet architecture on the given dataset.
Run the model for minimum 2 epochs and present your result. The solution will be evaluated based on approach only as it take lot of epochs to produce good result.

import os
import cv2
from PIL import Image
import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
import segmentation_models as sm
from sklearn.model_selection import train_test_split
from PIL import Image
from tensorflow.keras.utils import normalize
Segmentation Models: using `tf.keras` framework.
# hint : uncomment  below to fetch path
image_dir='Unet_Dataset/CXR_png/'
mask_dir='Unet_Dataset/masks/'
SIZE=128
#Read all the data from both the folders X-ray images and mask images.

# store the data in the following folders
img_dataset=[]
mask_dataset=[]

#Read the X-ray images and masks from the directories; hint: images=os.listdir(image_dir) and masks=os.listdir(mask_dir)
images=os.listdir(image_dir)
for i,image_name in enumerate(images):
    if (image_name.split('.')[1]=='png'):
        image=cv2.imread(image_dir+image_name,0)
        image=Image.fromarray(image)
        image=image.resize((SIZE,SIZE))
        img_dataset.append(np.array(image))

# Do the similar steps for masks, make sure your mask images are binary images.
images=os.listdir(mask_dir)
for i,image_name in enumerate(images):
    if (image_name.split('.')[1]=='png'):
        image=cv2.imread(mask_dir+image_name,0)
        image=Image.fromarray(image)
        image=image.resize((SIZE,SIZE))
        mask_dataset.append(np.array(image))
print(len(img_dataset), len(mask_dataset))

# convert the image data to array format and normalize/scale using (tensorflow.keras.utils.normalize()) function or (image data/255.)
img_dataset = tf.keras.utils.normalize(img_dataset)
mask_dataset = tf.keras.utils.normalize(mask_dataset)
fig, ax = plt.subplots(2,1)
ax[0].imshow(img_dataset[0])
ax[1].imshow(mask_dataset[0])
plt.show()

# split the data into train test with following specifications
#Hint: train_test_split(img_dataset,mask_dataset,test_size=0.20,random_state=0)
X_train, X_test, y_train, y_test = train_test_split(img_dataset,mask_dataset,test_size=0.20,random_state=42)
#take the pre-trained model as resnet34 and do pre-processing
BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)
# use the preprocessed train input for model fitting
X_train_prepr = preprocess_input(X_train)
X_test_prepr = preprocess_input(X_test)
#load the Unet model using the below syntax
model= sm.Unet(BACKBONE, input_shape=(128,128,1),
                                encoder_weights=None, classes=1, activation='sigmoid')
# Model compilation with the following specifications
#Hint: optimizer='Adam'
#    loss=sm.losses.bce_jaccard_loss
#    metrics=[sm.metrics.iou_score])
model.summary()

# fit the model for X_train_prepr and y_train.
# use batch_size=2 and epochs=5 (maximum)
model.compile(optimizer='Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])
model.fit(X_train_prepr, y_train, batch_size=2, epochs=50, validation_data=(X_test_prepr, y_test))

output = model.predict(X_test_prepr)
output.shape
(4, 128, 128, 1)
plt.imshow(output[1])

plt.imshow(y_test[1])



