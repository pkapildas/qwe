df17 = pd.read_csv(path17) ; 
df1 = df17.copy()
df1 = df1.rename(columns=({'Text':'Review'}))
df1=df1.drop(columns=['Id', 'Unnamed: 0'] , axis=1)
#df1 = df1.drop_duplicates(())
df1.head(2)

############## STEP 0 : Clean Text, Preprocessing  ################

############# 1 Clean the Text ##################
stop_words=set(stopwords.words('english'))
stop_words.discard('no')
stop_words.discard('not')
def func_clean_text(text):
    text   = text.lower()
    text   = unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8')
    text   = re.sub(r'http\S+|www\S+', '', text)  # Remove URLs
    text   = re.sub(r'\d','',text)                # Remove digits
    text   = text.translate(str.maketrans('','',string.punctuation))    # Remove punctuation
    tokens = [word for word in nltk.word_tokenize(text)                            if word not in stop_words]
    #tokens = [nltk.PorterStemmer().stem(word) for word in nltk.word_tokenize(text) if word not in stop_words]
    #tokens = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in nltk.word_tokenize(text)         if word not in stop_words]
    text   = ' '.join(tokens)                     
    text   = re.sub(r'\s+',' ',text).strip()       # Eliminate multiple spaces
    return text
df1['Clean_text']=df1['Review'].apply(func_clean_text)


################# 2  Polarity & Subjectivity & Sentiment #####
def getTextSubjectivity(txt):
    return TextBlob(txt).sentiment.subjectivity

def getTextPolarity(txt):
    return TextBlob(txt).sentiment.polarity

def getTextSentiment(a):
    if a < 0:
        return "Negative"
    elif a == 0:
        return "Neutral"
    else:
        return "Positive"

df1['Polarity'    ]   = df1['Clean_text'].transform(lambda x: getTextPolarity(str(x)))
df1['Subjectivity']   = df1['Clean_text'].transform(lambda x: getTextSubjectivity(str(x)))
df1['Sentiment'   ]   = df1['Polarity'].apply(getTextSentiment)
df1['ScoreEncoded']   = df1['Score']-1
df1['ScoreEncoded']   = df1['ScoreEncoded'].astype(int)
display(df1.head(2))


#df1['Emotion'] = df1['Polarity'].apply(lambda x: 'Positive' if x>3 else 'Negative') ; #data.head()

############ 3 Questions on Sentiment Analysis ########
a= df1[df1['Sentiment'] == 'Positive']
b = a.shape[0]/(df1.shape[0])*100
print(b , " % of positive Review")

#Visualize the frequency distribution of the sentiment on each content
plt.figure(figsize = (4,2))
labels = df1.groupby('Sentiment').count().index.values
values = df1.groupby('Sentiment').size().values
plt.bar(labels, values); plt.show();

#################### 4 Similar words to food [CBOW, Word to vec] ##########################
df_tokenize = df1['Clean_text'].apply(nltk.word_tokenize)          ## tokenized words
# df_tokenize = [text.split() for text in df1['Clean_text']]

model=Word2Vec(df_tokenize, window=5,sg=1,vector_size=100,min_count=1,epochs=300) ;  
similar_words = model.wv.most_similar(positive=['food'],topn=5) ; print(similar_words)


############## STEP 1 : Feature Engineering  ###############

#TF-IDF values are not raw counts but normalized weights,
############## 5 Count Vectoriser : Top 6 most frequent words  ################
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd

#model          = CountVectorizer()                       # common words dominate    #SPAM/HAM
model           = TfidfVectorizer()                       # reduce importance common words dominate   
model_fit       = model.fit_transform(df1['Clean_text'])  # tv.toarray()[:2]
vocabulary      = model.get_feature_names_out()           # Retrieve the feature names (words)
term_importance = model_fit.sum(axis=0)                   # Sum the occurrences of each word across all documents
word_freq_df    = pd.DataFrame({'Word': vocabulary, 'Frequency': term_importance .A1})
word_freq_df    = word_freq_df.sort_values(by='Frequency', ascending=False)

model_shape     = word_freq_df.shape           ; print(model_shape)      # top 5 word
top_5_words     = word_freq_df.head(6) ; print(top_5_words)      # top 5 word
importance_of_food = word_freq_df[word_freq_df['Word'] =='food'] # checking importance of word "food"
print(importance_of_food)

####################### Section C ################################
####################### Train Test ###############################
# Convert text into numerical representations (CountVectorizer & TF-IDF)
vectorizer_count = CountVectorizer()
vectorizer_tfidf = TfidfVectorizer()

X_count = vectorizer_count.fit_transform(df1['Clean_text'])
X_tfidf = vectorizer_tfidf.fit_transform(df1['Clean_text'])
y = df1['Review']

# Split dataset (Ensuring stratified sampling)
X_train_count, X_test_count, y_train, y_test = train_test_split(X_count, df1['Sentiment'] , test_size=0.25, stratify= df1['Sentiment'], random_state=42)
X_train_tfidf, X_test_tfidf,  _     , _      = train_test_split(X_tfidf, df1['Sentiment'] , test_size=0.25, stratify= df1['Sentiment'], random_state=42)

####################### LR, Naive Bayas ###############################
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Logistic Regression Model
def train_model(model_class, X_train, X_test, y_train, y_test, model_type):
    model = model_class
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\n{model_type} {model_class} Accuracy:", accuracy)
    return model  

# Train & Evaluate Logistic Regression
train_model(LogisticRegression(), X_train_count, X_test_count, y_train, y_test, "Count-Vectorized")
train_model(LogisticRegression(), X_train_tfidf, X_test_tfidf, y_train, y_test, "TF-IDF")
train_model(MultinomialNB()     , X_train_count, X_test_count, y_train, y_test, "Count-Vectorized")
#train_model(MultinomialNB()    , X_train_tfidf, X_test_tfidf, y_train, y_test, "TF-IDF")

#---------------------------------------------------------------------------------------------------------------------------------------------------




import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Flatten, BatchNormalization, Bidirectional, SpatialDropout1D
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import regularizers
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load dataset
df  = pd.read_csv('/content/drive/MyDrive/dataset/july24_data_set.csv')
df = df.rename(columns=({'Text':'Review'}))
df = df.drop(columns=['Id', 'Unnamed: 0'] , axis=1)
#df = df.drop_duplicates(())


############# 1 Clean the Text ##################
stop_words=set(stopwords.words('english'))
stop_words.discard('no')
stop_words.discard('not')
def func_clean_text(text):
    text   = text.lower()
    text   = unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8')
    text   = re.sub(r'http\S+|www\S+', '', text)  # Remove URLs
    text   = re.sub(r'\d','',text)                # Remove digits
    text   = text.translate(str.maketrans('','',string.punctuation))    # Remove punctuation
    tokens = [word for word in nltk.word_tokenize(text)                            if word not in stop_words]
    #tokens = [nltk.PorterStemmer().stem(word) for word in nltk.word_tokenize(text) if word not in stop_words]
    #tokens = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in nltk.word_tokenize(text)         if word not in stop_words]
    text   = ' '.join(tokens)
    text   = re.sub(r'\s+',' ',text).strip()       # Eliminate multiple spaces
    return text
df['Clean_text']=df['Review'].apply(func_clean_text)

# Tokenization
print("Tokenizing text...")
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(df['Clean_text'])
sequences = tokenizer.texts_to_sequences(df['Clean_text'])

# Sequence Padding
max_len = max([len(seq) for seq in sequences])
embed_dim = 100  # Own embedding size
vocab_size = len(tokenizer.word_index) + 1
print(f'The max sentence length: {max_len}, Unique words: {vocab_size}')

# Padding Sequences
padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')

# Label Encoding
y = df['Score']
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Splitting Data
xtrain, xtest, ytrain, ytest = train_test_split(padded_sequences, y_encoded, test_size=0.3, random_state=48, stratify=y_encoded)

# Encoding Labels for LSTM
ytrain_en = to_categorical(ytrain, num_classes=len(np.unique(y_encoded)))
ytest_en = to_categorical(ytest, num_classes=len(np.unique(y_encoded)))

# Building LSTM Model
print("Building LSTM Model...")
model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_len))

model.add(SpatialDropout1D(0.2))
model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))

#model.add(LSTM(64, activation='tanh', kernel_regularizer=regularizers.l2(0.01), return_sequences=True))
#model.add(Dropout(0.2))
#model.add(LSTM(32, activation='tanh'))
#model.add(Flatten())

model.add(Dense(64, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.2))
model.add(Dense(32, activation='relu'))
model.add(Dense(len(np.unique(y_encoded)), activation='softmax'))


# Compile Model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Train Model with Early Stopping
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
history = model.fit(xtrain, ytrain_en, batch_size=32, epochs=10, validation_data=(xtest, ytest_en), callbacks=[early_stopping])

# Predict
test_predictions = model.predict(xtest)
ypred_pr = np.argmax(test_predictions, axis=1)

# Model Evaluation
print(f"Length of X_test: {len(xtest)}")
print(f"Length of y_test: {len(ytest)}")
print(f"Length of predictions: {len(ypred_pr)}")
print(f"Model Accuracy: {accuracy_score(ytest, ypred_pr) * 100:.2f}%")

# Confusion Matrix & Classification Report
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(ytest, ypred_pr), annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_.astype(str), yticklabels=label_encoder.classes_.astype(str))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print("Classification Report:")
print(classification_report(ytest, ypred_pr, target_names=label_encoder.classes_.astype(str)))
=====================
######################## This layout represents how the data flows through the Transformer network with a focus on attention
Inputs
  ↓
Input Embedding
  ↓
Positional Encoding
  ↓
--------------------------------------
| Nx times:                           |
| Multi-Head Attention  → Add & Norm  |
| Feed Forward          → Add & Norm  |
---------------------------------------
  ↓
Output Embedding
  ↓
Positional Encoding
  ↓
-------------------------------------------------------
| Nx times:                                           |
| Masked Multi-Head Attention → Add & Norm            |
| Multi-Head Attention       → Add & Norm             |
| Feed Forward               → Add & Norm             |
-------------------------------------------------------
  ↓
Linear
  ↓
Softmax
  ↓
Output Probabilities


#################################

# Scaled Dot-Product Attention

Q, K, V
  ↓
MatMul
  ↓
Scale
  ↓
(Optional) Mask
  ↓
SoftMax
  ↓
MatMul
  ↓
Output

#####################################
# Multi-Head Attention

Q      K      V
↓      ↓      ↓
Linear Linear Linear
↓      ↓      ↓
Scaled Dot-Product Attention
↓
Concat
↓
Linear
↓
Output



=====
Tokenize
data_list = list()
for comp in complaint_to_words:
    data_list.append(RegexpTokenizer('\w+').tokenize(comp))
#lower case
low=[]
for line in data_list:
  lines = list(map(lambda x : x.lower(),line))
  low.append(lines) 
print(low[:3])
print(len(low[0])) 
#Removing Punctuatio
#nltk.download('punkt')
stop_words = set(stopwords.words('english')) 
puncList = [";",":","!","?","/","\\",",","#","@","$","&",")","(","\""]

#word_tokens = word_tokenize(text_tokens) 

Punc_filtered_sentence = [] 

for lines in low:
  punc = []
  for w in lines: 
      if w not in puncList: 
          punc.append(w) 
  Punc_filtered_sentence.append(punc)
print(len(Punc_filtered_sentence[0])) 

#Stop Word Removal
import nltk
from nltk.corpus import stopwords
#nltk.download('stopwords')

from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 
    
stop_words = set(stopwords.words('english')) 
    
filtered_sentence = [] 

for lines in Punc_filtered_sentence:
  word = []
  for w in lines: 
      if w not in stop_words: 
          word.append(w) 
  filtered_sentence.append(word)

print(len(Punc_filtered_sentence[0])) 
print(len(filtered_sentence[0])) 
#Stemming & Lemitization
from nltk.stem import PorterStemmer
porter = PorterStemmer()
# Stemming

stemmed=[]
for line in filtered_sentence:
  lines = list(map(lambda x : porter.stem(x),line))
  stemmed.append(lines) 
print(len(filtered_sentence[0])) 
print(len(stemmed[0]))
print(filtered_sentence[0]) 
print(stemmed[0])
Lemitization
#nltk.download('wordnet')
from nltk.stem.wordnet import WordNetLemmatizer
lmtzr = WordNetLemmatizer()

# Lemitization

lemmitized=[]
for line in stemmed:
  lines = list(map(lambda x : lmtzr.lemmatize(x),line))
  lemmitized.append(lines)
print(stemmed[0]) 
print(lemmitized[0])

PoS
nltk.pos_tag(lemmitized[0])
Voc = []
for line in lemmitized:
  Voc.extend(line)
print(Voc[:20])

#unicode file to ascii
import unicodedata

# Converts the unicode file to ascii
def unicode_to_ascii(s):
    return ''.join(c for c in unicodedata.normalize('NFD', s)
        if unicodedata.category(c) != 'Mn')
 2.Preprocessing the sentence
import re

def preprocess_sentence(w):
    w = unicode_to_ascii(w.lower().strip())
    
    # creating a space between a word and the punctuation following it
    # eg: "he is a boy." => "he is a boy ." 
    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation
    w = re.sub(r"([?.!,¿])", r" \1 ", w)
    w = re.sub(r'[" "]+', " ", w)
    
    # replacing everything with space except (a-z, A-Z, ".", "?", "!", ",")
    #w = re.sub(r"[^a-zA-Z?.!,¿]+", " ", w) # COMMENT THIS LINE FOR NON-LATIN SCRIPTS SUCH AS MARATHI, HINDI ETC.
    
    w = w.rstrip().strip()
    
    # adding a start and an end token to the sentence
    # so that the model know when to start and stop predicting.
    w = '<start> ' + w + ' <end>'
    return w

Create Data Set
# 1. Remove the accents
# 2. Clean the sentences
# 3. Return word pairs in the format: [ENGLISH, MARATHI]
def create_dataset(path, num_examples):
    lines = open(path, encoding='UTF-8').read().strip().split('\n')
    
    word_pairs = [[preprocess_sentence(w) for w in l.split('\t')]  for l in lines[:num_examples]]
    
    return word_pairs
create_dataset(path_to_file, num_examples=10)
Define a class to create a word -> index mapping
# This class creates a word -> index mapping (e.g,. "dad" -> 5) and vice-versa 
# (e.g., 5 -> "dad") for each language,
class LanguageIndex():
  def __init__(self, lang):
    self.lang = lang
    self.word2idx = {}
    self.idx2word = {}
    self.vocab = set()
    
    self.create_index()
    
  def create_index(self):
    for phrase in self.lang:
      self.vocab.update(phrase.split(' '))
    
    self.vocab = sorted(self.vocab)
    
    self.word2idx['<pad>'] = 0
    for index, word in enumerate(self.vocab):
      self.word2idx[word] = index + 1
    
    for word, index in self.word2idx.items():
      self.idx2word[index] = word

def max_length(tensor):
    return max(len(t) for t in tensor)


def load_dataset(path, num_examples):
    # creating cleaned input, output pairs
    pairs = create_dataset(path, num_examples)

    # index language using the class defined above    
    inp_lang = LanguageIndex(mr for en, mr in pairs)
    targ_lang = LanguageIndex(en for en, mr in pairs)
    
    # Vectorize the input and target languages
    
    # Other language sentences
    input_tensor = [[inp_lang.word2idx[s] for s in mr.split(' ')] for en, mr in pairs]
    
    # English sentences
    target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')] for en, mr in pairs]
    
    # Calculate max_length of input and output tensor
    # Here, we'll set those to the longest sentence in the dataset
    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)
    
    # Padding the input and output tensor to the maximum length
    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, 
                                                                 maxlen=max_length_inp,
                                                                 padding='post')
    
    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, 
                                                                  maxlen=max_length_tar, 
                                                                  padding='post')
    
    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar
# Try experimenting with the size of that dataset
num_examples = 30000
input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(path_to_file, num_examples)
# Split data into train and test
from sklearn.model_selection import train_test_split

# Creating training and validation sets using an 90-10 split
input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)

# Show length
len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)
Consider the dataset into different batches
BUFFER_SIZE = len(input_tensor_train)
BATCH_SIZE = 64
N_BATCH = BUFFER_SIZE//BATCH_SIZE
embedding_dim = 256
units = 1024
vocab_inp_size = len(inp_lang.word2idx)
vocab_tar_size = len(targ_lang.word2idx)

dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)
dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)
Define an Encoder function¶
class Encoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):
        super(Encoder, self).__init__()
        self.batch_sz = batch_sz
        self.enc_units = enc_units
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(self.enc_units, 
                                    return_sequences=True, 
                                    return_state=True, 
                                    recurrent_initializer='glorot_uniform')
        
    def call(self, x, hidden):
        x = self.embedding(x)
        output, state = self.gru(x, initial_state = hidden)        
        return output, state
    
    def initialize_hidden_state(self):
        return tf.zeros((self.batch_sz, self.enc_units))

class Decoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):
        super(Decoder, self).__init__()
        self.batch_sz = batch_sz
        self.dec_units = dec_units
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(self.dec_units, 
                                    return_sequences=True, 
                                    return_state=True, 
                                    recurrent_initializer='glorot_uniform')
        
        self.fc = tf.keras.layers.Dense(vocab_size)
        
        # used for attention
        self.W1 = tf.keras.layers.Dense(self.dec_units)
        self.W2 = tf.keras.layers.Dense(self.dec_units)
        self.W3 = tf.keras.layers.Dense(self.dec_units)
        self.W4 = tf.keras.layers.Dense(self.dec_units)

        self.V = tf.keras.layers.Dense(1)
        
    def call(self, x, hidden, enc_output):
        # enc_output shape == (batch_size, max_length, hidden_size)
        
        # hidden shape == (batch_size, hidden size)
        # hidden_with_time_axis shape == (batch_size, 1, hidden size)
        # we are doing this to perform addition to calculate the score
        hidden_with_time_axis = tf.expand_dims(hidden, 1)
        
        # score shape == (batch_size, max_length, 1)
        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V
        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))
        
        # attention_weights shape == (batch_size, max_length, 1)
        attention_weights = tf.nn.softmax(score, axis=1)
        
        # context_vector shape after sum == (batch_size, hidden_size)
        context_vector = attention_weights * enc_output
        context_vector = tf.reduce_sum(context_vector, axis=1)
        
        # x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding(x)
        
        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)
        
        # passing the concatenated vector to the GRU
        output, state = self.gru(x)
        
        # output shape == (batch_size * 1, hidden_size)
        output = tf.reshape(output, (-1, output.shape[2]))
        
        # output shape == (batch_size * 1, vocab)
        x = self.fc(output)
        
        return x, state, attention_weights
        
    def initialize_hidden_state(self):
        return tf.zeros((self.batch_sz, self.dec_units))
encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)
decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)

# Define loss function 
import numpy as np

def loss_function(real, pred):
  mask = 1 - np.equal(real, 0)
  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask
  return tf.reduce_mean(loss_)
import os
optimizer = tf.optimizers.Adam()

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(optimizer=optimizer,
                                 encoder=encoder,
                                 decoder=decoder)
Compile encoder-decoder-loss function


import time

EPOCHS = 50

for epoch in range(EPOCHS):
    start = time.time()
    
    hidden = encoder.initialize_hidden_state()
    total_loss = 0
    
    for (batch, (inp, targ)) in enumerate(dataset):
        loss = 0
        
        with tf.GradientTape() as tape:
            enc_output, enc_hidden = encoder(inp, hidden)
            
            dec_hidden = enc_hidden
            
            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       
            
            # Teacher forcing - feeding the target as the next input
            for t in range(1, targ.shape[1]):
                # passing enc_output to the decoder
                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)
                
                loss += loss_function(targ[:, t], predictions)
                
                # using teacher forcing
                dec_input = tf.expand_dims(targ[:, t], 1)
        
        batch_loss = (loss / int(targ.shape[1]))
        
        total_loss += batch_loss
        
        variables = encoder.variables + decoder.variables
        
        gradients = tape.gradient(loss, variables)
        
        optimizer.apply_gradients(zip(gradients, variables))
        
        if batch % 100 == 0:
            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,
                                                         batch,
                                                         batch_loss.numpy()))
    # saving (checkpoint) the model every 2 epochs
    if (epoch + 1) % 2 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)
    
    print('Epoch {} Loss {:.4f}'.format(epoch + 1,
                                        total_loss / N_BATCH))
    print('Time taken for 1 epoch {} sec\n'.format(time.time() - start))
checkpoint.save(file_prefix = checkpoint_prefix)
Defie an evaluation function
def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):
    attention_plot = np.zeros((max_length_targ, max_length_inp))
    
    sentence = preprocess_sentence(sentence)

    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]
    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')
    inputs = tf.convert_to_tensor(inputs)
    
    result = ''

    hidden = [tf.zeros((1, units))]
    enc_out, enc_hidden = encoder(inputs, hidden)

    dec_hidden = enc_hidden
    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)

    for t in range(max_length_targ):
        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)
        
        # storing the attention weigths to plot later on
        attention_weights = tf.reshape(attention_weights, (-1, ))
        attention_plot[t] = attention_weights.numpy()

        predicted_id = tf.argmax(predictions[0]).numpy()

        result += targ_lang.idx2word[predicted_id] + ' '

        if targ_lang.idx2word[predicted_id] == '<end>':
            return result, sentence, attention_plot
        
        # the predicted ID is fed back into the model
        dec_input = tf.expand_dims([predicted_id], 0)

    return result, sentence, attention_plot
Define a function for plotting the weights
import matplotlib.pyplot as plt

# function for plotting the attention weights
def plot_attention(attention, sentence, predicted_sentence):
    fig = plt.figure(figsize=(10,10))
    ax = fig.add_subplot(1, 1, 1)
    ax.matshow(attention, cmap='viridis')
    
    fontdict = {'fontsize': 14}
    
    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)
    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)

    plt.show()
.Define a translate function
def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):
    print('Input: {}'.format(sentence))
    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)
        
    print('Input: {}'.format(sentence))
    print('Predicted translation: {}'.format(result))
    
    attention_plot = attention_plot[:len(result.split(' '))-1, :len(sentence.split(' '))-1]
    plot_attention(attention_plot, sentence.split(' '), result.split(' '))
# restoring the latest checkpoint in checkpoint_dir
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
translate('এটি একটি খুব গুরুত্বপূর্ণ শিক্ষা', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)



--------------------
Key Differences Between RNN, LSTM,  
Architecture:

RNN: Simple recurrent connections, prone to vanishing gradient problems.
LSTM: Complex architecture with memory cells and three types of gates, designed to capture long-term dependencies.
 Learning Capabilities:

RNN: Good for short-term dependencies.
LSTM: Superior for long-term dependencies and handling complex sequences.
 Training Complexity:

RNN: Easier to implement but struggles with long-term dependencies.
LSTM: More complex and computationally intensive, requires careful tuning.
 Applications of RNNs, LSTMs,  
RNN:

Example: Predicting stock prices based on short-term trends.
Scenario: Simple sequence modeling tasks where long-term dependencies are less critical.
LSTM:

Example: Machine translation and language modeling.
Scenario: Tasks requiring the capture of long-term dependencies and context over longer sequences.
 

RNN: Simplicity, effective for basic sequential tasks.
LSTM: Powerful for complex sequences, handles long-term dependencies well.

Challenges:

RNN: Vanishing gradient problem, limited to short-term dependencies.
LSTM: High computational cost, complexity in tuning.

Conclusion
Understanding the differences between RNN, LSTM, and   is crucial for selecting the right model for sequential data tasks. 
Each type has unique strengths and challenges, making them suitable for different applications. By mastering these architectures, 


#stemming and lemmatization
stemming and lemmatization are two essential techniques used to transform words into their base or root forms. These processes aid in reducing the dimensionality of text data and are employed in various NLP applications such as information retrieval, sentiment analysis, and machine learning. Despite sharing the common goal of reducing words to their base forms, stemming and lemmatization have distinct approaches and outcomes. In this article, we will delve into the dissimilarities between stemming and lemmatization, along with illustrative examples.

Stemming: Stemming is a technique where words are reduced to their base or root form by removing suffixes or prefixes. The resulting stem may not necessarily be a valid word on its own, but it can represent multiple related words. The process is relatively simple and involves applying predefined rules to trim common affixes. Stemming is generally faster than lemmatization due to its rule-based nature.
Example: Consider the following words: “running,” “runner,” and “runs.” After stemming, they would all be reduced to the common stem “run.”

Original Words: running, runner, runs

Stemmed Words: run, run, run

2. Lemmatization: Lemmatization, on the other hand, is a more sophisticated technique that transforms words to their base forms, known as lemmas, considering the word’s meaning and context. Unlike stemming, lemmatization ensures that the resulting lemma is a valid word, and it typically involves using a vocabulary or dictionary to map a word to its lemma.

Example: Let’s consider the same words as before: “running,” “runner,” and “runs.” After lemmatization, they will be reduced to different lemmas based on their respective parts of speech and context.

Original Words: running, runner, runs

Lemmatized Words: run, runner, run

In this example, “running” remains unchanged, as it is already in its base form (a verb in the present participle form). “Runner” remains “runner” since it is a noun, and the plural form “runs” becomes “run,” the base form of the verb.

Lemmatization is computationally expensive since it involves look-up tables and what not. If you have large dataset and performance is an issue, go with Stemming. Remember you can also add your own rules to Stemming. If accuracy is paramount and dataset isn't humongous, go with Lemmatization.



Word2Vec (word to vector) is a technique used to convert words to vectors, thereby capturing their meaning, semantic similarity, and relationship with surrounding text. This method helps computers learn the context and connotation of expressions and keywords from large text collections such as news articles and books.

The basic idea behind Word2Vec is to represent each word as a multi-dimensional vector, where the position of the vector in that high-dimensional space captures the meaning of the word.
Word2Vec’s meaningful embedding goes beyond traditional word vectorization methods like latent semantic analysis (LSA), singular value decomposition (SVD), or global vectors for word representation (GloVe), which existed before its introduction in 2013. Here’s why.

Word2Vec creates numerical vectors in a high-dimensional space while preserving the semantic and syntactic relationships between them.
This concept is more effective than any of its predecessors, as it simplifies the representation of relationships by encoding them into fixed-sized vectors and reducing the dimensionality of the space involved. This simplification makes mathematical analysis easier.
This technique can be applied to textual data and non-textual data, providing a tool to compare different things and identify similarities, whether it be goods, chemical compounds, gene sequences, or business concepts.
Word2Vec enables training contextualized models using open-source code optimized for speed and efficiency on specific data sets. For example, if your target data is in finance, you can use a model trained on the finance corpus
Has difficulty handling unknown words
Doesn’t have shared representations at sub-word levels

Difficult to scale to new languages

Word Embedding is an approach for representing words and documents. Word Embedding or Word Vector is a numeric vector input that represents a word in a lower-dimensional space. It allows words with similar meanings to have a similar representation.

Word Embeddings are a method of extracting features out of text so that we can input those features into a machine learning model to work with text data. They try to preserve syntactical and semantic information. The methods such as Bag of Words (BOW), 
CountVectorizer and TFIDF rely on the word count in a sentence but do not save any syntactical or semantic information. 
In these algorithms, the size of the vector is the number of elements in the vocabulary.
Need for Word Embedding?
To reduce dimensionality
To use a word to predict the words around it.
Inter-word semantics must be captured.
How are Word Embeddings used?
They are used as input to machine learning models.
Take the words —-> Give their numeric representation —-> Use in training or inference.
To represent or visualize any underlying patterns of usage in the corpus that was used to train them

Modern Natural Language Processing (NLP) uses word embeddings that have been previously trained on a large corpus of text and are hence called 
‘Pre-trained Word Embeddings.’ Pre-trained word embeddings are a type of Transfer Learning.
They are trained on large datasets that can enhance the performance of a Natural Language Processing (NLP) model because they capture both 
the connotative and syntactic meaning of a word. 
All of these word embeddings are useful during hackathons and in real-world scenarios.
