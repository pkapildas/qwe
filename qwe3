Build a Convolution Neural Network to classify 6 classes of chess game images.
Parameters should not cross 300000
- Should not use more than 4 layers (except input and output, including convolution and dense layers)
- Use Adam Optimizer

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

# Load Data
train_dir="Chess/Train"
test_dir="Chess/Test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen=ImageDataGenerator(rescale=1/255.)
test_datagen=ImageDataGenerator(rescale=1/255.)


train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=32,
                                             class_mode='categorical')

test_data=test_datagen.flow_from_directory(test_dir,
                                           target_size=(128,128),
                                           batch_size=32,
                                           class_mode='categorical')

# Build Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
base_model=Sequential([
                    Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),
                    MaxPool2D(),
                    Conv2D(16,3,activation='relu'),
                    MaxPool2D(),
                    Flatten(),
                    Dense(6, activation='softmax')

])

base_model.compile(loss='categorical_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

base_model.summary()

# fit model 
base_model.fit(train_data, epochs=10,
            steps_per_epoch=len(train_data),
            validation_data=test_data,
            validation_steps=len(test_data))
# EvaluateModel
base_model.evaluate(test_data)
# With respect to the above architecture, the model is overfitting
3 Improve the baseline model performance and save the weights of improved model
Conditions to consider:
Apply Data Augmentation if required
No parameter limit
Can use any number of layers
Use any optimizers of your choice
Use early stopping and save best model callbacks

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen=ImageDataGenerator(rescale=1/255.,
                                rotation_range=45,
                                width_shift_range=0.2,
                                height_shift_range=0.2,
                                shear_range=0.2,
                                zoom_range=0.2,
                                horizontal_flip=True,
                                fill_mode='reflect')

train_datagen=ImageDataGenerator(rescale=1/255.,zoom_range=0.2)


test_datagen=ImageDataGenerator(rescale=1/255.)
train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(128,128),
                                             batch_size=64,
                                             class_mode='categorical')

test_data=test_datagen.flow_from_directory(test_dir,
                                           target_size=(128,128),
                                           batch_size=64,
                                           class_mode='categorical')

model1=Sequential([
                    Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),
                    Conv2D(32,3,activation='relu'),
                    MaxPool2D(),
                    Conv2D(64,3,activation='relu'),
                    MaxPool2D(),
                    Flatten(),
                    Dropout(0.2),
                    Dense(64,activation='relu'),
                    Dropout(0.2),
                    Dense(32,activation='relu'),
                    Dense(6, activation='softmax')

])


keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01),
                ModelCheckpoint('flower_best_transfer_model',monitor='val_loss',save_best_only=True)]

model1.compile(loss='categorical_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])
#model1.summary()
model1.fit(train_data, epochs=10,
            steps_per_epoch=len(train_data),
            validation_data=test_data,
            validation_steps=len(test_data),callbacks=keras_callback)

# The overfitting is reduced, but model performance is not improved , it is undesrfitting , 
  # but it is for only 10 epoch, changing the architecture may help,
  # So running this for more epoch may imprrove performance.
# Dataset size is very less, so transfer learning may help

# Students can use differnt combinations of layers to improve the model performance.
# Also more epochs will improve the model, but students dont have time for it in exam
# Need to award mark for an approach

Section C: Question 4:
Use the Transfer learning technique to improve the previous section model’s classification performance.

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

train_dir="Chess/Train"
test_dir="Chess/Test"


from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)

test_datagen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)


train_data=train_datagen.flow_from_directory(train_dir,
                                             target_size=(224,224),
                                             batch_size=32,
                                             class_mode='categorical')

test_data=test_datagen.flow_from_directory(test_dir,
                                           target_size=(224,224),
                                           batch_size=32,
                                           class_mode='categorical')


import tensorflow as tf
Base_model=tf.keras.models.load_model("base_model")

for layer_number, layer in enumerate(Base_model.layers):
    print(layer_number, layer.name, layer.trainable)


Base_model.summary()

inputs=tf.keras.layers.Input(shape=(224,224,3),name='input_layer')

#data_aug=data_augmentation(inputs)

x=Base_model(inputs,training=False)

p=tf.keras.layers.GlobalAveragePooling2D()(x)

outputs=tf.keras.layers.Dense(6,activation='softmax',name="output_layer")(p)

model=tf.keras.Model(inputs,outputs)

model.summary()


model.compile(loss="categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=['accuracy'])
keras_callback=[EarlyStopping(monitor='val_loss',mode='min',patience=5,min_delta=0.01),
                ModelCheckpoint('flower_best_transfer_model',monitor='val_loss',save_best_only=True)]

history=model.fit(train_data,
                                         epochs=10,
                                         steps_per_epoch=len(train_data),
                                         validation_data=test_data,
                                         validation_steps=len(test_data),
                                         callbacks=keras_callback)

model.evaluate(test_data)
2s 676ms/step - loss: 0.9240 - accuracy: 0.6829
[0.9239882230758667, 0.6829268336296082]
validation loss is significantly reduced, but still model is overfitting, dropout and unfreezing batch normalization of convolution layer may help to reduce overfitting

Transfer learning with fine-tuning may also help

Section C: Question 5: (15 Marks)
Develop a Semantic segmentation model using Unet architecture on the given dataset.

import os
import cv2
from PIL import Image
import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
import segmentation_models as sm
from sklearn.model_selection import train_test_split
from PIL import Image
from tensorflow.keras.utils import normalize
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"

image_dir='Unet_Dataset/glioma_img/'

mask_dir='Unet_Dataset/glioma_mask/'


SIZE=128 # for a quick training, for medical images it is better to keep image size big as it is

img_dataset=[]
mask_dataset=[]

images=os.listdir(image_dir)

for i,image_name in enumerate(images):
    if (image_name.split('.')[1]=='jpg'):
        image=cv2.imread(image_dir+image_name,0)
        
        image=Image.fromarray(image)
        image=image.resize((SIZE,SIZE))
        img_dataset.append(np.array(image))
        #img_dataset.append(image)

       
        
masks=os.listdir(mask_dir)

for i,image_name in enumerate(masks):
    if (image_name.split('.')[1]=='jpg'):
        image=cv2.imread(mask_dir+image_name,0)
        image=cv2.resize(image,(SIZE,SIZE))
        (thresh, bwimage) = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY) # make sure mask is binary image
        #bwimage=Image.fromarray(bwimage)
        #mask_dataset.append(np.array(bwimage))
        mask_dataset.append(bwimage)

img_dataset=np.array(img_dataset)
img_dataset=normalize(img_dataset)
img_dataset=np.expand_dims(img_dataset,3)

mask_dataset=np.array(mask_dataset)
mask_dataset=mask_dataset/255.
mask_dataset=np.expand_dims(mask_dataset,3)

print(img_dataset.shape)

print(mask_dataset.shape)

np.unique(mask_dataset[0,:,:,0]) # make sure mask is having only 0 and 1 for binary class

r1=np.random.randint(1,705,size=(1,2))
r1[0][0],r1[0][1]


r1=np.random.randint(1,705,size=(1,2))
plt.figure(figsize=(10,6))
plt.subplot(2,2,1)
plt.imshow(img_dataset[r1[0][0],:,:,:].reshape(128,128),cmap='gray')
plt.subplot(2,2,2)
plt.imshow(mask_dataset[r1[0][0],:,:,:].reshape(128,128),cmap='gray')
plt.subplot(2,2,3)
plt.imshow(img_dataset[r1[0][1],:,:,:].reshape(128,128),cmap='gray')
plt.subplot(2,2,4)
plt.imshow(mask_dataset[r1[0][1],:,:,:].reshape(128,128),cmap='gray')


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(img_dataset,mask_dataset,test_size=0.15,random_state=0)

BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)

# preprocess input
X_train_prepr = preprocess_input(x_train)
X_test_prepr = preprocess_input(x_test)

del(x_train)
del(x_test)
np.unique(y_test)

#model_resnet_backbone= sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True,classes=n_classes,activation='softmax')
model_resnet_backbone = sm.Unet(BACKBONE, input_shape=(128,128,1), encoder_weights=None, classes=1, activation='sigmoid')

#model_seg.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
#model_seg.compile(optimizer = 'adam', loss = [jacard_coef_loss], metrics = [jacard_coef])
model_resnet_backbone.compile('Adam',loss=sm.losses.bce_jaccard_loss,metrics=[sm.metrics.iou_score])
#model_resnet_backbone.compile('Adam',loss=sm.losses.bce_jaccard_loss,metrics=[sm.metrics.iou_score])

X_train_prepr.shape


history=model_resnet_backbone.fit(X_train_prepr, 
         y_train,
         batch_size=2, 
         epochs=3,
         verbose=1,
         validation_data=(X_test_prepr, y_test))

#model_seg.compile(optimizer='Adam', loss=tf.keras.losses.BinaryCrossentropy())

n1=np.random.randint(0,len(X_test_prepr))
#n1=152
test_img=X_test_prepr[n1]
test_img1=np.expand_dims(test_img,0)
pred_img=model_resnet_backbone.predict(test_img1)
pred_img1=(pred_img[0,:,:,0]>0.5).astype(np.uint8)

plt.figure(figsize=(16,8))
plt.subplot(131)
plt.title('Original')
plt.imshow(test_img[:,:,0],cmap='gray')

plt.subplot(132)
plt.title('Mask Original')
plt.imshow(y_test[n1][:,:,0],cmap='gray')

plt.subplot(133)
plt.title('Segmented Image')
plt.imshow(pred_img1,cmap='gray')

-----
1. a) What are the causes of overfitting in a deep learning model?
High Model Complexity: Too many parameters compared to the amount of training data.
Insufficient Training Data: Not enough data to generalize well.
Noise in Training Data: Model learns noise and random fluctuations as patterns.
Lack of Regularization: No constraints on the model complexity.
Methods to Resolve Overfitting:
Dropout: Randomly dropping neurons during training to prevent co-adaptation.
Early Stopping: Monitoring the validation loss and stopping training when it starts increasing.

1. b) What is the usage of Convolution layer, pooling layer and dense layer in
Convolution Neural Network (CNN) architecture?
Convolution Layer: Extracts features from the input image by applying filters.
Pooling Layer: Reduces spatial dimensions, lowering the computational complexity and helping
with translation invariance.
Dense Layer (Fully Connected Layer): Combines features and makes predictions by learning
complex patterns.

1. c) What is the Vanishing Gradient Problem in deep learning models? How to get rid
of this?
Vanishing Gradient Problem: Gradients become very small during backpropagation, preventing
effective learning.
Solutions:
Use of Activation Functions like ReLU: Helps maintain gradients during backpropagation.
Batch Normalization: Normalizes inputs to each layer, reducing the risk of vanishing
gradients.
Weight Initialization Techniques: Proper initialization (e.g., He or Xavier initialization) to
maintain gradient magnitude.

1. d) List down various performance metrics used for object detection. What is the use
of non-maximal suppression in Object detection algorithms?
Performance Metrics:
Mean Average Precision (mAP): Measures the average precision across all classes.
Intersection over Union (IoU): Measures overlap between predicted and ground truth
boxes.
Precision and Recall: Evaluates the accuracy and completeness of the detections.
Non-Maximal Suppression (NMS):
Used to remove duplicate bounding boxes for the same object.
Keeps the box with the highest confidence score and suppresses the others.
1. e) What is the requirement of an activation function in deep neural network
architecture?
Introduces non-linearity, enabling the model to learn complex patterns.
Allows stacking multiple layers to form deep neural networks.
Activation Functions:
Tanh(): Ranges from -1 to 1, used in hidden layers for zero-centered output.
ReLU (Rectified Linear Unit): Outputs 0 for negative values, otherwise linear. Efficient and
reduces vanishing gradients.
Softmax(): Converts logits into probabilities, used in the output layer for multi-class
classification.

2. a) Explain the convolutional neural network architecture in detail.
Input Layer: Takes input images as a 3D matrix (height, width, channels).
Convolutional Layers: Extracts features using filters/kernels.
Activation Functions (e.g., ReLU): Introduces non-linearity.
Pooling Layers: Downsamples feature maps for spatial invariance.
Fully Connected Layers: Combines features and makes predictions.
Output Layer: Generates final predictions (e.g., using Softmax for classification).

2. b) Explain overfitting in neural networks? How to overcome the problem?
Overfitting: Model performs well on training data but poorly on new data.
Solutions:
Regularization (L1/L2): Adds a penalty for large weights.
Data Augmentation: Increases training data diversity.
Dropout: Randomly drops neurons during training.

2. c) What are the activation functions in neural networks? What is the use of these
activation functions?
Purpose: Introduce non-linearity, enabling the network to learn complex patterns.
Common Activation Functions:
Sigmoid: Outputs between 0 and 1, used in binary classification.
Tanh: Outputs between -1 and 1, zero-centered.
ReLU: Efficient and reduces vanishing gradient issues.
Softmax: Converts logits into probabilities for multi-class classification.

2. d) What is the difference between single stage and multi stage object detection
models?
Single Stage (e.g., YOLO, SSD):
Directly predicts bounding boxes and class probabilities.
Faster but less accurate for small objects.
Multi Stage (e.g., Faster R-CNN):
Two-stage process: Region Proposal followed by classification.
More accurate but slower due to the additional processing stage.

2. e) Briefly explain GANs? What are their advantages?
Generative Adversarial Networks (GANs):
Consists of a Generator and a Discriminator network.
Generator creates fake data, while Discriminator distinguishes between real and fake data.
Both networks are trained in a competitive manner.
Advantages:
Realistic Data Generation: High-quality synthetic data creation (e.g., images, music).
Data Augmentation: Useful for training models with limited data.
Creative Applications: Used in art generation, image super-resolution, and style transfer.

Explain the convolutional neural network architecture in detail.
A convolutional neural network (CNN), is a network architecture for deep learning which learns directly from data. CNNs are particularly useful for finding patterns in images to recognize objects.
They can also be quite effective for classifying non-image data such as audio, time series, and signal data

Kernel or Filter or Feature Detectors
In a convolutional neural network, the kernel is nothing but a filter that is used to extract the features from the images.

Formula = [i-k]+1

Stride
Stride is a parameter of the neural network’s filter that modifies the amount of movement over the image or video. we had stride 1 so it will take one by one. If we give stride 2 then it will take value by skipping the next 2 pixels.

Formula =[i-k/s]+1
Padding
Padding is a term relevant to convolutional neural networks as it refers to the number of pixels added to an image when it is being processed by the kernel of a CNN. For example, if the padding in a CNN is set to zero, then every pixel value that is added will be of value zero. When we use the filter or Kernel to scan the image, the size of the image will go smaller.

Pooling
Pooling in convolutional neural networks is a technique for generalizing features extracted by convolutional filters and helping the network recognize features independent of their location in the image.
Flatten
Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. The flattened matrix is fed as input to the fully connected layer to classify the image.
Layers used to build CNN
Convolutional neural networks are distinguished from other neural networks by their superior performance with image, speech, or audio signal inputs. They have three main types of layers, which are:

Convolutional layer
This layer is the first layer that is used to extract the various features from the input images. In this layer, We use a filter or Kernel method to extract features from the input image.
Pooling layer
The primary aim of this layer is to decrease the size of the convolved feature map to reduce computational costs. This is performed by decreasing the connections between layers and independently operating on each feature map. Depending upon the method used, there are several types of Pooling operations. We have Max pooling and average pooling.
Fully-connected (FC) layer
The Fully Connected (FC) layer consists of the weights and biases along with the neurons and is used to connect the neurons between two different layers. These layers are usually placed before the output layer and form the last few layers of a CNN Architecture.
Dropout
Another typical characteristic of CNNs is a Dropout layer. The Dropout layer is a mask that nullifies the contribution of some neurons towards the next layer and leaves unmodified all others.
Activation Function
An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuron’s input to the network is important or not in the process of prediction. There are several commonly used activation functions such as the ReLU, Softmax, tanH, and the Sigmoid functions. Each of these functions has a specific usage.


Activation Function
An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuron’s input to the network is important or not in the process of prediction. There are several commonly used activation functions such as the ReLU, Softmax, tanH, and the Sigmoid functions. Each of these functions has a specific usage.

